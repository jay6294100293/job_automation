name: Deploy Django Job Automation with n8n Monitoring

on:
  push:
    branches: [ main, master ]  # ‚úÖ FIXED: Added master branch support
  pull_request:
    branches: [ main, master ]
  workflow_dispatch:  # Allows manual triggering

env:
  REGISTRY: ghcr.io
  IMAGE_NAME: ${{ github.repository }}

jobs:
  test:
    runs-on: ubuntu-latest

    services:
      postgres:
        image: postgres:15
        env:
          POSTGRES_PASSWORD: postgres
          POSTGRES_USER: postgres
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: '3.11'

    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install -r requirements.txt
        pip install pytest-django pytest-cov coverage flake8

    - name: Create test environment  # ‚úÖ FIXED: Proper test environment setup
      run: |
        cat > .env << 'EOF'
        DEBUG=True
        DJANGO_SECRET_KEY=test-secret-key-for-github-actions
        SECRET_KEY=test-secret-key-for-github-actions
        DATABASE_URL=postgresql://postgres:postgres@localhost:5432/test_db
        REDIS_URL=redis://localhost:6379/0
        MONITORING_API_KEY=test-monitoring-key
        ALLOWED_HOSTS=localhost,127.0.0.1
        # Database settings for testing
        DB_NAME=test_db
        DB_USER=postgres
        DB_PASSWORD=postgres
        DB_HOST=localhost
        DB_PORT=5432
        REDIS_PASSWORD=
        CELERY_BROKER_URL=redis://localhost:6379/0
        CELERY_RESULT_BACKEND=redis://localhost:6379/0
        # AI API Keys (dummy for testing)
        GROQ_API_KEY=test_groq_key
        OPENROUTER_API_KEY=test_openrouter_key
        BREVO_LOGIN=test@example.com
        BREVO_SMTP_KEY=test_smtp_key
        EOF

    - name: Run migrations
      run: |
        python manage.py migrate --noinput

    - name: Run tests with coverage  # ‚úÖ FIXED: Proper test execution
      id: test_results
      run: |
        # Run your comprehensive test suite
        python manage.py test tests.test_models tests.test_views tests.test_api tests.test_ai_integration tests.test_n8n_integration --verbosity=2 || true
        
        # Also run pytest for any pytest-specific tests
        python -m pytest tests/ --cov=. --cov-report=xml --junitxml=test-results.xml -v || true
        
        # Extract test results for monitoring
        if [ -f "test-results.xml" ]; then
          TOTAL_TESTS=$(python -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('test-results.xml')
              root = tree.getroot()
              print(root.attrib.get('tests', '0'))
          except:
              print('0')
          ")
          
          FAILED_TESTS=$(python -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('test-results.xml')
              root = tree.getroot()
              print(root.attrib.get('failures', '0'))
          except:
              print('0')
          ")
          
          PASSED_TESTS=$((TOTAL_TESTS - FAILED_TESTS))
        else
          TOTAL_TESTS=0
          FAILED_TESTS=0
          PASSED_TESTS=0
        fi
        
        # Get coverage
        COVERAGE=0
        if [ -f "coverage.xml" ]; then
          COVERAGE=$(python -c "
          import xml.etree.ElementTree as ET
          try:
              tree = ET.parse('coverage.xml')
              root = tree.getroot()
              coverage = float(root.attrib.get('line-rate', '0')) * 100
              print(f'{coverage:.2f}')
          except:
              print('0')
          ")
        fi
        
        # Calculate pass rate
        if [ "$TOTAL_TESTS" -gt 0 ]; then
          PASS_RATE=$(echo "scale=2; $PASSED_TESTS * 100 / $TOTAL_TESTS" | bc)
        else
          PASS_RATE=0
        fi
        
        echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
        echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
        echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
        echo "coverage=$COVERAGE" >> $GITHUB_OUTPUT
        echo "pass_rate=$PASS_RATE" >> $GITHUB_OUTPUT

    - name: Check code style
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics || true

    - name: Send Test Results to n8n
      if: always()
      run: |
        TEST_DATA=$(cat <<EOF
        {
          "event_id": "test_${{ github.run_id }}_${{ github.run_attempt }}",
          "repository": "${{ github.repository }}",
          "branch": "${{ github.ref_name }}",
          "commit_sha": "${{ github.sha }}",
          "workflow_run_id": "${{ github.run_id }}",
          "total_tests": ${{ steps.test_results.outputs.total_tests }},
          "passed": ${{ steps.test_results.outputs.passed_tests }},
          "failed": ${{ steps.test_results.outputs.failed_tests }},
          "skipped": 0,
          "pass_rate": ${{ steps.test_results.outputs.pass_rate }},
          "coverage": ${{ steps.test_results.outputs.coverage }},
          "timestamp": "$(date -Iseconds)",
          "workflow_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}"
        }
        EOF
        )
        
        echo "Sending test results to n8n..."
        curl -X POST \
          -H "Content-Type: application/json" \
          -d "$TEST_DATA" \
          "https://ai.jobautomation.me/webhook/test-results" \
          --max-time 30 || echo "Failed to send to n8n"

  build-and-push:
    needs: test
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'  # ‚úÖ FIXED: Support both branches

    permissions:
      contents: read
      packages: write

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Set up Docker Buildx
      uses: docker/setup-buildx-action@v3

    - name: Log in to Container Registry
      uses: docker/login-action@v3
      with:
        registry: ${{ env.REGISTRY }}
        username: ${{ github.actor }}
        password: ${{ secrets.GITHUB_TOKEN }}

    - name: Extract metadata
      id: meta
      uses: docker/metadata-action@v5
      with:
        images: ${{ env.REGISTRY }}/${{ env.IMAGE_NAME }}
        tags: |
          type=ref,event=branch
          type=sha
          type=raw,value=latest,enable={{is_default_branch}}

    - name: Build and push Docker image
      uses: docker/build-push-action@v5
      with:
        context: .
        push: true
        tags: ${{ steps.meta.outputs.tags }}
        labels: ${{ steps.meta.outputs.labels }}
        cache-from: type=gha
        cache-to: type=gha,mode=max

  deploy:
    needs: [test, build-and-push]
    runs-on: ubuntu-latest
    if: github.ref == 'refs/heads/main' || github.ref == 'refs/heads/master'  # ‚úÖ FIXED: Support both branches

    environment:
      name: production
      url: https://ai.jobautomation.me

    steps:
    - name: Checkout code
      uses: actions/checkout@v4

    - name: Deploy to DigitalOcean  # ‚úÖ FIXED: Proper deployment with correct git branch
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ${{ secrets.DO_HOST }}
        username: ${{ secrets.DO_USERNAME }}
        key: ${{ secrets.DO_SSH_KEY }}
        script: |
          set -e
          
          # Navigate to app directory
          cd /opt/job_automation
          
          echo "üöÄ Starting deployment..."
          
          # Pull latest changes from the correct branch
          git fetch origin
          git checkout master  # ‚úÖ FIXED: Use master branch
          git pull origin master  # ‚úÖ FIXED: Use master branch
          
          # Login to GitHub Container Registry
          echo ${{ secrets.GITHUB_TOKEN }} | docker login ghcr.io -u ${{ github.actor }} --password-stdin
          
          # Pull latest images
          docker compose pull django || docker-compose pull django
          
          echo "üì¶ Creating backup..."
          # Create database backup before deployment
          docker exec job_automation_postgres_1 pg_dump -U django_user job_automation > /opt/backups/pre_deploy_$(date +%Y%m%d_%H%M%S).sql 2>/dev/null || echo "Backup failed, continuing..."
          
          echo "üîÑ Deploying new version..."
          # Deploy with zero downtime
          docker compose up -d --no-deps django || docker-compose up -d --no-deps django
          
          echo "üîß Running post-deployment tasks..."
          # Wait for Django to be ready
          sleep 30
          
          # Run migrations
          docker compose exec -T django python manage.py migrate --noinput || docker-compose exec -T django python manage.py migrate --noinput
          
          # Collect static files
          docker compose exec -T django python manage.py collectstatic --noinput || docker-compose exec -T django python manage.py collectstatic --noinput
          
          # Restart related services
          docker compose restart celery celery-beat || docker-compose restart celery celery-beat
          
          echo "üßπ Cleaning up..."
          # Clean up old images
          docker image prune -af
          
          echo "‚úÖ Deployment completed!"

    - name: Health Check
      id: health_check
      run: |
        echo "üè• Performing health check..."
        sleep 60
        
        HEALTH_STATUS=$(curl -s "https://ai.jobautomation.me/health/" | jq -r '.status' 2>/dev/null || echo "unknown")
        echo "health_status=$HEALTH_STATUS" >> $GITHUB_OUTPUT
        
        if [ "$HEALTH_STATUS" != "healthy" ]; then
          echo "‚ùå Health check failed!"
          curl -f https://ai.jobautomation.me/health/ || exit 1
        else
          echo "‚úÖ Health check passed!"
        fi

    - name: Send Deployment Status to n8n
      if: always()
      run: |
        if [ "${{ job.status }}" == "success" ] && [ "${{ steps.health_check.outputs.health_status }}" == "healthy" ]; then
          DEPLOY_STATUS="success"
          SEVERITY="low"
        else
          DEPLOY_STATUS="failed"
          SEVERITY="high"
        fi
        
        DEPLOYMENT_DATA=$(cat <<EOF
        {
          "event_id": "deploy_${{ github.run_id }}_${{ github.run_attempt }}",
          "repository": "${{ github.repository }}",
          "branch": "${{ github.ref_name }}",
          "commit_sha": "${{ github.sha }}",
          "author": "${{ github.actor }}",
          "workflow_run_id": "${{ github.run_id }}",
          "status": "$DEPLOY_STATUS",
          "severity": "$SEVERITY",
          "deployment_url": "https://ai.jobautomation.me",
          "health_status": "${{ steps.health_check.outputs.health_status }}",
          "timestamp": "$(date -Iseconds)",
          "workflow_url": "https://github.com/${{ github.repository }}/actions/runs/${{ github.run_id }}",
          "environment": "production"
        }
        EOF
        )
        
        echo "Sending deployment status to n8n..."
        curl -X POST \
          -H "Content-Type: application/json" \
          -d "$DEPLOYMENT_DATA" \
          "https://ai.jobautomation.me/webhook/deployment-status" \
          --max-time 30 || echo "Failed to send to n8n"

    - name: Notify Discord
      if: always()
      uses: sarisia/actions-status-discord@v1
      with:
        webhook: ${{ secrets.DISCORD_WEBHOOK }}
        status: ${{ job.status }}
        title: "üöÄ Django Job Automation Deployment"
        description: |
          **Repository:** ${{ github.repository }}
          **Branch:** ${{ github.ref_name }}
          **Commit:** ${{ github.sha }}
          **Author:** ${{ github.actor }}
          **Status:** ${{ job.status }}
          **Health:** ${{ steps.health_check.outputs.health_status }}
          **URL:** https://ai.jobautomation.me
        color: ${{ job.status == 'success' && 0x00ff00 || 0xff0000 }}

  post-deployment-monitoring:
    needs: [deploy]
    runs-on: ubuntu-latest
    if: always()

    steps:
    - name: Wait for services to stabilize
      run: sleep 60

    - name: Collect and send server metrics
      uses: appleboy/ssh-action@v1.0.3
      with:
        host: ${{ secrets.DO_HOST }}
        username: ${{ secrets.DO_USERNAME }}
        key: ${{ secrets.DO_SSH_KEY }}
        script: |
          # Install bc if not available
          which bc >/dev/null || (apt-get update && apt-get install -y bc)
          
          # Function to get server metrics
          get_server_metrics() {
            # CPU usage
            CPU_USAGE=$(top -bn1 | grep "Cpu(s)" | awk '{print $2}' | sed 's/%us,//' | sed 's/[^0-9.]//g')
            [ -z "$CPU_USAGE" ] && CPU_USAGE=0
            
            # Memory usage
            MEMORY_INFO=$(free | grep '^Mem:')
            TOTAL_MEM=$(echo $MEMORY_INFO | awk '{print $2}')
            USED_MEM=$(echo $MEMORY_INFO | awk '{print $3}')
            MEMORY_USAGE=$(echo "scale=2; $USED_MEM * 100 / $TOTAL_MEM" | bc 2>/dev/null || echo "0")
            
            # Disk usage
            DISK_USAGE=$(df / | awk 'NR==2 {print $5}' | sed 's/%//')
            [ -z "$DISK_USAGE" ] && DISK_USAGE=0
            
            # Container stats
            if command -v docker &> /dev/null; then
              CONTAINERS_RUNNING=$(docker ps -q | wc -l)
              CONTAINERS_TOTAL=$(docker ps -a -q | wc -l)
            else
              CONTAINERS_RUNNING=0
              CONTAINERS_TOTAL=0
            fi
            
            # Load average
            LOAD_AVG=$(uptime | awk -F'load average:' '{print $2}' | xargs)
            
            # Uptime
            UPTIME=$(uptime -p)
            
            # Create metrics JSON
            METRICS_DATA=$(cat <<EOFMETRICS
          {
            "event_id": "post_deploy_${{ github.run_id }}_$(date +%s)",
            "hostname": "$(hostname)",
            "cpu_usage": $CPU_USAGE,
            "memory_usage": $MEMORY_USAGE,
            "disk_usage": $DISK_USAGE,
            "load_average": "$LOAD_AVG",
            "uptime": "$UPTIME",
            "containers_running": $CONTAINERS_RUNNING,
            "containers_total": $CONTAINERS_TOTAL,
            "timestamp": "$(date -Iseconds)",
            "deployment_related": true,
            "workflow_run_id": "${{ github.run_id }}"
          }
          EOFMETRICS
            )
            
            echo "Server Metrics: $METRICS_DATA"
            
            # Send to n8n webhook
            curl -X POST \
              -H "Content-Type: application/json" \
              -d "$METRICS_DATA" \
              "https://ai.jobautomation.me/webhook/server-metrics" \
              --max-time 30 || echo "Failed to send metrics to n8n"
          }
          
          # Collect and send metrics
          get_server_metrics